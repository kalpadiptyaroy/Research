{"cells":[{"metadata":{},"cell_type":"markdown","source":"Detecting COVID-19 with Chest X Ray using PyTorch\n\nImage classification of Chest X Rays in one of three classes: Normal, Viral Pneumonia, COVID-19\n\nNotebook created for the guided project [Detecting COVID-19 with Chest X Ray using PyTorch](https://www.coursera.org/projects/covid-19-detection-x-ray) on Coursera\n\nDataset from [COVID-19 Radiography Dataset](https://www.kaggle.com/tawsifurrahman/covid19-radiography-database) on Kaggle\n\nI have modified it as per my requirements and the Dataset I am using is IEEE Dataset available on github. "},{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport os\nimport shutil\nimport random\nimport torch\nimport torchvision\nimport numpy as np\n\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n\ntorch.manual_seed(0)\n\nprint('Using PyTorch version', torch.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparing Training and Test Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = ['Covid', 'Non-covid']  # we have two classes covid and non-covid\nroot_dir = 'Dataset'\nsource_dirs = ['Covid', 'Non-Covid']  # these are dirs where the labels images are stored. Names are co-incidentally same with that of class names.\n\nif os.path.isdir(os.path.join(root_dir, source_dirs[1])):\n    os.mkdir(os.path.join(root_dir, 'test'))\n\n    for i, d in enumerate(source_dirs):\n        os.rename(os.path.join(root_dir, d), os.path.join(root_dir, class_names[i]))\n\n    for c in class_names:\n        os.mkdir(os.path.join(root_dir, 'test', c))\n\n    for c in class_names:\n        images = [x for x in os.listdir(os.path.join(root_dir, c)) if (x[-3:].lower().endswith('png') or x[-3:].lower().endswith('jpg') or x[-4:].lower().endswith('jpeg'))]\n        selected_images = random.sample(images, 30)\n        for image in selected_images:\n            source_path = os.path.join(root_dir, c, image)\n            target_path = os.path.join(root_dir, 'test', c, image)\n            shutil.move(source_path, target_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Custom Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ChestXRayDataset(torch.utils.data.Dataset):\n    def __init__(self, image_dirs, transform):\n        def get_images(class_name):\n            images = [x for x in os.listdir(image_dirs[class_name]) if (x[-3:].lower().endswith('png') or x[-3:].lower().endswith('jpg') or x[-4:].lower().endswith('jpeg')) ] \n            print(f'Found {len(images)} {class_name} examples')\n            return images\n        \n        self.images = {}\n        self.class_names = ['Covid', 'Non-Covid']\n        \n        for c in self.class_names:\n            self.images[c] = get_images(c)\n            \n        self.image_dirs = image_dirs\n        self.transform = transform\n        \n    def __len__(self):\n        return sum([len(self.images[c]) for c in self.class_names])\n    \n    def __getitem__(self, index):\n        class_name = random.choice(self.class_names)\n        index = index % len(self.images[class_name])\n        image_name = self.images[class_name][index]\n        image_path = os.path.join(self.image_dirs[class_name], image_name)\n        image = Image.open(image_path).convert('RGB')\n        return self.transform(image), self.class_names.index(class_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Transformations"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(size=(224,224)),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n])\n\ntest_transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(size=(224, 224)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare DataLoader"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dirs = {\n    'Covid': 'Dataset/Covid',\n    'Non-Covid' : 'Dataset/Non-Covid'\n}\n\ntrain_dataset = ChestXRayDataset(train_dirs, train_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dirs = {\n    'Covid': 'Dataset/test/Covid',\n    'Non-Covid' : 'Dataset/test/Non-Covid'\n}\n\ntest_dataset = ChestXRayDataset(test_dirs, test_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 6\n\ndl_train = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n\ndl_test = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = True)\n\nprint('Number of Training batches', len(dl_train))\nprint('Number of test batches', len(dl_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = train_dataset.class_names\n\ndef show_images(images, labels, preds):\n    plt.figure(figsize=(10, 4))\n    for i, image in enumerate(images):\n        plt.subplot(1, 6, i + 1, xticks=[], yticks=[])\n        image = image.numpy().transpose((1, 2, 0))\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = image * std + mean\n        image = np.clip(image, 0., 1.)\n        plt.imshow(image)\n        col = 'green' \n        if preds[i] != labels[i]:\n            col = 'red'\n        plt.xlabel(f'{class_names[int(labels[i].numpy())]}')\n        plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color=col)\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images, labels = next(iter(dl_train))\nshow_images(images, labels, labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images, labels = next(iter(dl_test))\nshow_images(images, labels, labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet18 = torchvision.models.resnet18(pretrained=True)\nprint(resnet18)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet18.fc = torch.nn.Linear(in_features=512, out_features=2)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet18.parameters(), lr=3e-5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_preds():\n    resnet18.eval() #We set the resnet18 model to evaluation mode.\n    images, labels = next(iter(dl_test))\n    outputs = resnet18(images)\n    _, preds = torch.max(outputs, 1)\n    show_images(images, labels, preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_preds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(epochs):\n    print('Starting Training ...')\n    accuracy_yaxis = []\n    val_loss_yaxis = []\n    steps_xaxis = []\n    for e in range(0, epochs):\n        print('_'*20)\n        print(f'Starting epoch {e + 1} / {epochs}')\n        print('_'*20)\n\n        train_loss, val_loss = 0, 0\n        resnet18.train() #we put the resnet model to train mode.\n\n        for train_step, (images, labels) in enumerate(dl_train):\n            optimizer.zero_grad() #Before training our gradient is always zero.\n            outputs = resnet18(images)\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            if train_step % 20 == 0:\n                print('Evaluating at step', train_step)\n                accuracy = 0\n                resnet18.eval() #We put the resnet18 model to evaluation mode.\n\n                for val_step, (images, labels) in enumerate(dl_test):\n                    outputs = resnet18(images)\n                    loss = loss_fn(outputs, labels)\n                    val_loss += loss.item()\n\n                    _, preds = torch.max(outputs, 1)\n                    accuracy += sum((preds == labels).numpy())\n\n                val_loss /= (val_step + 1)\n                accuracy = accuracy / len(test_dataset)\n                print(f'Validation Loss: {val_loss:.4f}, Accuracy:{accuracy:.4f}')\n                accuracy_yaxis.append(accuracy)\n                val_loss_yaxis.append(val_loss)\n                steps_xaxis.append(((len(dl_train) - 1) * e) + train_step)\n                show_preds()\n                resnet18.train()\n\n                if accuracy >= 0.97:\n                    print('Performance Condition Satisfied, Stopping ...')\n                    return\n                else:\n                    print(f'Accuracy: {accuracy:.4f}')\n\n        train_loss /= (train_step + 1)\n\n        print(f'Training Loss: {train_loss:.4f}')\n    print('Training Complete ....')\n    return (accuracy_yaxis, val_loss_yaxis, steps_xaxis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\naccuracy_yaxis, val_loss_yaxis, steps_xaxis = train(epochs = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_preds()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(steps_xaxis, val_loss_yaxis, label = 'validation loss')\nplt.plot(steps_xaxis, accuracy_yaxis, label = 'accuracy')\nplt.legend()\nplt.title('(Validation Loss , Accuracy) VS Train Step')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}